{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Pyspark_Linear Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_zupVz1F1Bc",
        "outputId": "58dcceb9-f0a9-4126-f668-dcc24c708079"
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,365 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,781 kB]\n",
            "Ign:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [443 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,690 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,208 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [865 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,130 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [54.3 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [252 kB]\n",
            "Fetched 11.1 MB in 3s (3,349 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrwkhhS0GAdL"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30st-SWQGChx"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqnY0qFsGGCL"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJsOlN8-GWW4"
      },
      "source": [
        "# **Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ9Sm_7QdEbP"
      },
      "source": [
        " build a Linear Regression model using Spark’s MLlib library and\n",
        "predict the target variable using the input features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rGssdKQdLkG"
      },
      "source": [
        "### Data Info\n",
        "The dataset that we are going to use for this example is a dummy\n",
        "dataset and contains a total of 1,232 rows and 6 columns. We have to\n",
        "use 5 input variables to predict the target variable using the Linear\n",
        "Regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l3UnbFxddsw"
      },
      "source": [
        "Step **1**: Create the SparkSession Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKNcQ0SOGXl5"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('lin_reg').getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6f8UqAdec0H"
      },
      "source": [
        "Step **2**: Read the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8I_N4b_GHAG"
      },
      "source": [
        "df = spark.read.csv('Linear_regression_dataset.csv',inferSchema=True,header=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXKBZMOtfJB-"
      },
      "source": [
        "Step **3**: Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDI-eglLfY4n",
        "outputId": "5cae5265-2a91-4950-b7d6-195b40134b2d"
      },
      "source": [
        "#the shape of the dataset\n",
        "print((df.count(), len(df.columns)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1232, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRp3ikSefxR-",
        "outputId": "30f5c13d-2d91-4e91-a014-16ea8d1b5472"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- var_1: integer (nullable = true)\n",
            " |-- var_2: integer (nullable = true)\n",
            " |-- var_3: integer (nullable = true)\n",
            " |-- var_4: double (nullable = true)\n",
            " |-- var_5: double (nullable = true)\n",
            " |-- output: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UuJVE0ugXf2",
        "outputId": "4821ade8-7f26-4f7f-c146-9a9cc19d5207"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
            "|summary|            var_1|            var_2|             var_3|               var_4|               var_5|             output|\n",
            "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
            "|  count|             1232|             1232|              1232|                1232|                1232|               1232|\n",
            "|   mean|715.0819805194806|715.0819805194806| 80.90422077922078|  0.3263311688311693| 0.25927272727272715|0.39734172077922014|\n",
            "| stddev| 91.5342940441652|93.07993263118064|11.458139049993724|0.015012772334166148|0.012907228928000298|0.03326689862173776|\n",
            "|    min|              463|              472|                40|               0.277|               0.214|              0.301|\n",
            "|    max|             1009|             1103|               116|               0.373|               0.294|              0.491|\n",
            "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGryfWpfgW8o"
      },
      "source": [
        "This allows us to get a sense of distribution, measure of center, and\n",
        "spread for our dataset columns. We then take a sneak peek into the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD_IM_CQgqlI",
        "outputId": "612b2b19-29c0-4728-ecba-6c9229491ee5"
      },
      "source": [
        "df.head(4)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(var_1=734, var_2=688, var_3=81, var_4=0.328, var_5=0.259, output=0.418),\n",
              " Row(var_1=700, var_2=600, var_3=94, var_4=0.32, var_5=0.247, output=0.389),\n",
              " Row(var_1=712, var_2=705, var_3=93, var_4=0.311, var_5=0.247, output=0.417),\n",
              " Row(var_1=734, var_2=806, var_3=69, var_4=0.315, var_5=0.26, output=0.415)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6oXCXz1fMRt"
      },
      "source": [
        "We can check the correlation between input variables and output\n",
        "variables using the corr function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73cKvxH_g8Sn",
        "outputId": "31b0c276-eae6-4beb-8352-4b5ea45aa731"
      },
      "source": [
        "from pyspark.sql.functions import corr\n",
        "df.select(corr('var_1','output')).show()\n",
        "#var_1 seems to be most strongly correlated with the output column."
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|corr(var_1, output)|\n",
            "+-------------------+\n",
            "| 0.9187399607627283|\n",
            "+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzTqPx18h7xM"
      },
      "source": [
        "Step **4**: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc-yMuoGjW10"
      },
      "source": [
        "This is the part where we create a single vector combining all input features\n",
        "by using Spark’s VectorAssembler. It creates only a single feature that\n",
        "captures the input values for that row. So, instead of five input columns, it\n",
        "essentially merges all input columns into a single feature vector column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z8xORcPjYB4"
      },
      "source": [
        "\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uzSv2VBjztg"
      },
      "source": [
        "One can select the number of columns that would be used as input\n",
        "features and can pass only those columns through the VectorAssembler. In\n",
        "our case, we will pass all the five input columns to create a single feature\n",
        "vector column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nul8dvmdj0aA",
        "outputId": "6d2e09b7-c177-4f81-8bf8-c36f750ef1d6"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'output']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SFE7fpSh-oH"
      },
      "source": [
        "vec_assembler = VectorAssembler(inputCols=['var_1', 'var_2', 'var_3', 'var_4', 'var_5'],outputCol='features')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJPDdJYVkaZR",
        "outputId": "fbddaa4c-a58a-4864-9801-3c290ea745c4"
      },
      "source": [
        "features_df= vec_assembler.transform(df)\n",
        "features_df.printSchema()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- var_1: integer (nullable = true)\n",
            " |-- var_2: integer (nullable = true)\n",
            " |-- var_3: integer (nullable = true)\n",
            " |-- var_4: double (nullable = true)\n",
            " |-- var_5: double (nullable = true)\n",
            " |-- output: double (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxYVJAxIkydR"
      },
      "source": [
        "As, we can see, we have an additional column (‘features’) that contains\n",
        "the single dense vector for all of the inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE6uuDl0kzD3",
        "outputId": "d111b851-9607-4b11-868b-7ad6b1d2c113"
      },
      "source": [
        "features_df.select('features').show(5)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|[734.0,688.0,81.0...|\n",
            "|[700.0,600.0,94.0...|\n",
            "|[712.0,705.0,93.0...|\n",
            "|[734.0,806.0,69.0...|\n",
            "|[613.0,759.0,61.0...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ootb9MxlCUN"
      },
      "source": [
        "We take the subset of the dataframe and select only the features\n",
        "column and the output column to build the Linear Regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HofcGREOlCxg",
        "outputId": "239aee10-47c2-4da9-d332-7d1764e0a7e3"
      },
      "source": [
        "model_df = features_df.select('features','output')\n",
        "model_df.show(5)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------+\n",
            "|            features|output|\n",
            "+--------------------+------+\n",
            "|[734.0,688.0,81.0...| 0.418|\n",
            "|[700.0,600.0,94.0...| 0.389|\n",
            "|[712.0,705.0,93.0...| 0.417|\n",
            "|[734.0,806.0,69.0...| 0.415|\n",
            "|[613.0,759.0,61.0...| 0.378|\n",
            "+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Luhqdv_lSrR",
        "outputId": "14869645-29b1-43cb-f8a0-4d1c50d8682c"
      },
      "source": [
        "print((model_df.count(),len(model_df.columns)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1232, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPvAD7tdlhhY"
      },
      "source": [
        "Step **5**: Splitting the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqAF8mnNlndp"
      },
      "source": [
        " We\n",
        "split it into a 70/30 ratio and train our model on 70% of the dataset. We can\n",
        "print the shape of train and test data to validate the size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JN1DYn1lg1r",
        "outputId": "4a4cebd4-0ff9-43cb-8236-56747e6381ce"
      },
      "source": [
        "train_df,test_df=model_df.randomSplit([0.7,0.3])\n",
        "print((train_df.count(),len(train_df.columns)))\n",
        "print((test_df.count(),len(test_df.columns)))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(864, 2)\n",
            "(368, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF3fl1femA8L"
      },
      "source": [
        "Step **6**: Build and Train Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh-RmmuwmV6M",
        "outputId": "47be46c5-c508-4851-e29f-cea3e6eb8cfd"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lin_Reg = LinearRegression(labelCol='output')\n",
        "lr_model = lin_Reg.fit(train_df)\n",
        "print(lr_model.coefficients)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0003374392956775735,5.160609482977743e-05,0.0001318541177160561,-0.628626969273809,0.5276636824697607]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZToC0vWnasa",
        "outputId": "5ddfe2f2-4ec3-4246-b206-ccb625d9a6db"
      },
      "source": [
        "print(lr_model.intercept)\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1768447412971254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvezCWufnh2r",
        "outputId": "6154c0e8-ad9d-4d0d-e897-1e8d2cf38579"
      },
      "source": [
        "trainning_predections=lr_model.evaluate(train_df)\n",
        "print(trainning_predections.r2)\n",
        "#This model gives a very good accuracy (86%)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8657799077266927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD63ae31oBIN"
      },
      "source": [
        "Step **7**: Evaluate Linear Regression Model\n",
        "on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvJ_LdYNnix-",
        "outputId": "798130f5-5005-4c4e-f6b4-6b1cf83f7029"
      },
      "source": [
        "test_predictions = lr_model.evaluate(test_df)\n",
        "print(test_predictions.r2)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.875806489988025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMB3FFS3oYQO",
        "outputId": "6763e236-6532-4901-adb0-369ecd939945"
      },
      "source": [
        "print(test_predictions.meanSquaredError)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001424534922119856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NomJxuFHmEhp"
      },
      "source": [
        ""
      ]
    }
  ]
}